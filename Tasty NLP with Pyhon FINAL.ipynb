{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schapira.d\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from random import sample\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "# nltk models\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#spaCy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# gensim models\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "# Visualize topics\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet spaCy - \"It's minimal and opinionated\"\n",
    "\n",
    "spaCy is a free, **open-source** library for advanced **Natural Language Processing (NLP)** in Python.\n",
    "\n",
    "Features:\n",
    "\n",
    "-  Tokenization\n",
    "-  POS Tagging\n",
    "-  Dependency Parsing\n",
    "-  Lemmatization\n",
    "-  Sentence Detection\n",
    "-  Entity Recognition\n",
    "\n",
    "And more...\n",
    "\n",
    "https://spacy.io/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = 'Best restaurant in Newcastle. Delicious cocktails and it has a really friendly atmosphere.'\n",
    "\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>token_entity</th>\n",
       "      <th>token_is_stop</th>\n",
       "      <th>token_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[-1.6054, 4.53702, -0.672109, -2.05529, -1.600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[1.33561, 0.368323, 2.64288, 0.373385, -2.4033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>[1.44569, 1.10417, -0.406471, 1.28426, 1.65253...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Newcastle</td>\n",
       "      <td>newcastle</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>GPE</td>\n",
       "      <td>False</td>\n",
       "      <td>[-2.38429, 0.409086, 3.07898, 0.594176, -0.754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[0.474397, 1.99392, 2.95767, -0.329908, 1.3399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delicious</td>\n",
       "      <td>delicious</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[-3.31449, 3.54701, -0.886751, 2.62596, -3.169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocktails</td>\n",
       "      <td>cocktail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[0.890365, 3.60857, -1.63054, -2.22932, 1.359,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>[0.74245, -1.03995, -0.239206, -1.88797, 2.333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>[-1.6597, 0.930871, 3.74128, 2.16395, -2.18548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>has</td>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>[-3.41011, 2.17194, -1.65569, -1.99658, 3.2991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>[2.64929, -2.16059, 1.57773, 7.26103, 6.65484,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>really</td>\n",
       "      <td>really</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0771762, -1.56962, -2.69741, 4.12226, 2.141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendly</td>\n",
       "      <td>friendly</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[-1.62595, -1.60285, -1.74331, 0.34037, -0.901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>atmosphere</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[0.667868, 0.940877, 1.00614, 1.26148, -1.2045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[3.50395, -0.748438, 1.81277, -1.85407, 1.1134...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_text token_lemma token_pos token_entity  token_is_stop  \\\n",
       "0         Best        good       ADJ                       False   \n",
       "1   restaurant  restaurant      NOUN                       False   \n",
       "2           in          in       ADP                        True   \n",
       "3    Newcastle   newcastle     PROPN          GPE          False   \n",
       "4            .           .     PUNCT                       False   \n",
       "5    Delicious   delicious     PROPN                       False   \n",
       "6    cocktails    cocktail      NOUN                       False   \n",
       "7          and         and     CCONJ                        True   \n",
       "8           it      -PRON-      PRON                        True   \n",
       "9          has        have      VERB                        True   \n",
       "10           a           a       DET                        True   \n",
       "11      really      really       ADV                        True   \n",
       "12    friendly    friendly       ADJ                       False   \n",
       "13  atmosphere  atmosphere      NOUN                       False   \n",
       "14           .           .     PUNCT                       False   \n",
       "\n",
       "                                            token_vec  \n",
       "0   [-1.6054, 4.53702, -0.672109, -2.05529, -1.600...  \n",
       "1   [1.33561, 0.368323, 2.64288, 0.373385, -2.4033...  \n",
       "2   [1.44569, 1.10417, -0.406471, 1.28426, 1.65253...  \n",
       "3   [-2.38429, 0.409086, 3.07898, 0.594176, -0.754...  \n",
       "4   [0.474397, 1.99392, 2.95767, -0.329908, 1.3399...  \n",
       "5   [-3.31449, 3.54701, -0.886751, 2.62596, -3.169...  \n",
       "6   [0.890365, 3.60857, -1.63054, -2.22932, 1.359,...  \n",
       "7   [0.74245, -1.03995, -0.239206, -1.88797, 2.333...  \n",
       "8   [-1.6597, 0.930871, 3.74128, 2.16395, -2.18548...  \n",
       "9   [-3.41011, 2.17194, -1.65569, -1.99658, 3.2991...  \n",
       "10  [2.64929, -2.16059, 1.57773, 7.26103, 6.65484,...  \n",
       "11  [0.0771762, -1.56962, -2.69741, 4.12226, 2.141...  \n",
       "12  [-1.62595, -1.60285, -1.74331, 0.34037, -0.901...  \n",
       "13  [0.667868, 0.940877, 1.00614, 1.26148, -1.2045...  \n",
       "14  [3.50395, -0.748438, 1.81277, -1.85407, 1.1134...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text = [token.text for token in doc]\n",
    "token_pos = [token.pos_ for token in doc]\n",
    "token_lemma = [token.lemma_ for token in doc]\n",
    "token_entity = [token.ent_type_ for token in doc]\n",
    "token_stop = [token.is_stop for token in doc]\n",
    "token_vec = [token.vector for token in doc]\n",
    "\n",
    "headers = ['token_text','token_lemma','token_pos','token_entity','token_is_stop','token_vec']\n",
    "\n",
    "pd.DataFrame(list(zip(token_text, token_lemma, token_pos, token_entity,token_stop,token_vec)),columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_head</th>\n",
       "      <th>token_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>[Best, in, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>[Newcastle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Newcastle</td>\n",
       "      <td>in</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delicious</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocktails</td>\n",
       "      <td>has</td>\n",
       "      <td>[Delicious, and, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>cocktails</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>has</td>\n",
       "      <td>has</td>\n",
       "      <td>[cocktails, atmosphere, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>really</td>\n",
       "      <td>friendly</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendly</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>[really]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>atmosphere</td>\n",
       "      <td>has</td>\n",
       "      <td>[a, friendly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>has</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_text  token_head              token_children\n",
       "0         Best  restaurant                          []\n",
       "1   restaurant  restaurant               [Best, in, .]\n",
       "2           in  restaurant                 [Newcastle]\n",
       "3    Newcastle          in                          []\n",
       "4            .  restaurant                          []\n",
       "5    Delicious   cocktails                          []\n",
       "6    cocktails         has        [Delicious, and, it]\n",
       "7          and   cocktails                          []\n",
       "8           it   cocktails                          []\n",
       "9          has         has  [cocktails, atmosphere, .]\n",
       "10           a  atmosphere                          []\n",
       "11      really    friendly                          []\n",
       "12    friendly  atmosphere                    [really]\n",
       "13  atmosphere         has               [a, friendly]\n",
       "14           .         has                          []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_head = [token.head for token in doc]\n",
    "token_children = [list(token.children) for token in doc]\n",
    "\n",
    "headers_ = ['token_text','token_head','token_children']\n",
    "\n",
    "pd.DataFrame(list(zip(token_text, token_head, token_children)),columns=headers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schapira.d\\AppData\\Local\\Continuum\\Anaconda3\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\schapira.d\\AppData\\Local\\Continuum\\Anaconda3\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1220\" height=\"317.0\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Best</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">restaurant</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">Newcastle.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Delicious</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">cocktails</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">has</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">really</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">friendly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">atmosphere.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,137.0 125.0,137.0 125.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M215.0,184.0 L223.0,172.0 207.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M250,182.0 C250,137.0 305.0,137.0 305.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M305.0,184.0 L313.0,172.0 297.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M430,182.0 C430,137.0 485.0,137.0 485.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M520,182.0 C520,47.0 765.0,47.0 765.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,184.0 L512,172.0 528,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M520,182.0 C520,137.0 575.0,137.0 575.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,184.0 L583.0,172.0 567.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M520,182.0 C520,92.0 670.0,92.0 670.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670.0,184.0 L678.0,172.0 662.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M880,182.0 C880,47.0 1125.0,47.0 1125.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M970,182.0 C970,137.0 1025.0,137.0 1025.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M970,184.0 L962,172.0 978,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M1060,182.0 C1060,137.0 1115.0,137.0 1115.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,184.0 L1052,172.0 1068,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M790,182.0 C790,2.0 1130.0,2.0 1130.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1130.0,184.0 L1138.0,172.0 1122.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Best restaurant,\n",
       " Newcastle,\n",
       " Delicious cocktails,\n",
       " it,\n",
       " a really friendly atmosphere]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Best restaurant in Newcastle.,\n",
       " Delicious cocktails and it has a really friendly atmosphere.]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "\n",
    "300 dimensions doc2vec as average of token vectors trained using GloVe on Common Crawl dataset\n",
    "\n",
    "https://en.wikipedia.org/wiki/Common_Crawl\n",
    "\n",
    "https://spacy.io/models/en#section-en_vectors_web_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = ['Pork is amazing','Sausage was great','Data Science made simple','Physics studies laws of the universe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_text</th>\n",
       "      <th>doc_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pork is amazing</td>\n",
       "      <td>[-0.332147, 0.185507, 0.2583, 0.130159, 0.1209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sausage was great</td>\n",
       "      <td>[-0.206415, 0.324179, 0.18584, 0.0150927, -7.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science made simple</td>\n",
       "      <td>[-0.26445, 0.0599757, -0.181192, 0.0580605, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physics studies laws of the universe</td>\n",
       "      <td>[0.0194767, 0.0151591, -0.171293, -0.183741, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doc_text  \\\n",
       "0                       Pork is amazing   \n",
       "1                     Sausage was great   \n",
       "2              Data Science made simple   \n",
       "3  Physics studies laws of the universe   \n",
       "\n",
       "                                             doc_vec  \n",
       "0  [-0.332147, 0.185507, 0.2583, 0.130159, 0.1209...  \n",
       "1  [-0.206415, 0.324179, 0.18584, 0.0150927, -7.1...  \n",
       "2  [-0.26445, 0.0599757, -0.181192, 0.0580605, -0...  \n",
       "3  [0.0194767, 0.0151591, -0.171293, -0.183741, -...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doc2vec(docs):\n",
    "\n",
    "    \"\"\"\n",
    "    Get doc2vec representations of docs using spaCy pre-trained word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_text = []\n",
    "    doc_vec = []\n",
    "\n",
    "    for doc in nlp.pipe(docs):\n",
    "        doc_text.append(doc.text)\n",
    "        doc_vec.append(doc.vector)\n",
    "    \n",
    "    headers = ['doc_text','doc_vec']\n",
    "\n",
    "    return pd.DataFrame(list(zip(doc_text, doc_vec)),columns=headers)\n",
    "\n",
    "df = doc2vec(docs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pork is amazing</th>\n",
       "      <th>Sausage was great</th>\n",
       "      <th>Data Science made simple</th>\n",
       "      <th>Physics studies laws of the universe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pork is amazing</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816263</td>\n",
       "      <td>0.543974</td>\n",
       "      <td>0.441451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sausage was great</th>\n",
       "      <td>0.816263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508645</td>\n",
       "      <td>0.422934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Science made simple</th>\n",
       "      <td>0.543974</td>\n",
       "      <td>0.508645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physics studies laws of the universe</th>\n",
       "      <td>0.441451</td>\n",
       "      <td>0.422934</td>\n",
       "      <td>0.744686</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pork is amazing  Sausage was great  \\\n",
       "Pork is amazing                              1.000000           0.816263   \n",
       "Sausage was great                            0.816263           1.000000   \n",
       "Data Science made simple                     0.543974           0.508645   \n",
       "Physics studies laws of the universe         0.441451           0.422934   \n",
       "\n",
       "                                      Data Science made simple  \\\n",
       "Pork is amazing                                       0.543974   \n",
       "Sausage was great                                     0.508645   \n",
       "Data Science made simple                              1.000000   \n",
       "Physics studies laws of the universe                  0.744686   \n",
       "\n",
       "                                      Physics studies laws of the universe  \n",
       "Pork is amazing                                                   0.441451  \n",
       "Sausage was great                                                 0.422934  \n",
       "Data Science made simple                                          0.744686  \n",
       "Physics studies laws of the universe                              1.000000  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "docvecs = df['doc_vec'].tolist()\n",
    "cos_sim = cosine_similarity(docvecs)\n",
    "df_sim = pd.DataFrame(cos_sim,columns=df['doc_text'].tolist(),index=df['doc_text'].tolist())\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build an NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>stars_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vXEZ-r6fah-5Fjt3a6c-Gw</td>\n",
       "      <td>\"The Cheesecake Factory\"</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>American (Traditional);Desserts;Food;American ...</td>\n",
       "      <td>One of my favorite places too take the kids wh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name        city  \\\n",
       "0  vXEZ-r6fah-5Fjt3a6c-Gw  \"The Cheesecake Factory\"  Pittsburgh   \n",
       "\n",
       "                                          categories  \\\n",
       "0  American (Traditional);Desserts;Food;American ...   \n",
       "\n",
       "                                                text  stars_x  \n",
       "0  One of my favorite places too take the kids wh...        4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "path = 'C:\\\\Users\\\\schapira.d\\\\Desktop\\\\Data Science Meetup\\\\yelp_reviews_1M.csv'\n",
    "reviews_df = pd.read_csv(path,encoding='utf-8')\n",
    "reviews = reviews_df['text'].fillna('').tolist()\n",
    "ratings = reviews_df['stars_x'].tolist()\n",
    "reviews_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def TextPreprocessSpaCy(docs):\n",
    "    text = []\n",
    "    pos = ['ADJ','NOUN']\n",
    "    stop = ['-pron-']\n",
    "    for doc in nlp.pipe(docs):\n",
    "        tokens = [token.lemma_.lower() for token in doc if token.pos_ in pos and token.is_stop == False] \n",
    "        tokens = [i for i in tokens if i not in stop]\n",
    "        text.append(tokens)\n",
    "                \n",
    "    return text\n",
    "\n",
    "def TextPreprocessNLTK(docs):\n",
    "    text = []\n",
    "    stop = stopwords.words('english')\n",
    "    lemma = WordNetLemmatizer()\n",
    "    pos = ['JJ','JJR','JJS','NN','NNS']\n",
    "    \n",
    "    for i in docs:\n",
    "        tokens = word_tokenize(i.lower()) # tokenize\n",
    "        tokens = pos_tag(tokens) # POS tagger\n",
    "        tokens = [i[0] for i in tokens if i[1] in pos] # POS filter\n",
    "        tokens = [i for i in tokens if i not in string.punctuation] # remove punctuation\n",
    "        tokens = [i for i in tokens if i not in stop] # remove stopwords\n",
    "        tokens = [lemma.lemmatize(i) for i in tokens] # lemmatize\n",
    "        text.append(tokens)\n",
    "        \n",
    "    return text\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'place', 'sushi', 'area', 'everything', 'fresh', 'chef', 'pride', 'piece', 'sushi'] \n",
      " --SpaCy Run time: 6.964414119720459s\n",
      "\n",
      "['best', 'place', 'sushi', 'area', 'everything', 'fresh', 'chef', 'piece', 'sushi'] \n",
      " --NLTK Run time: 7.787414073944092s\n",
      "\n",
      "By far the best place to get sushi in the area.  Everything is fresh and you can tell that the chef takes pride in each piece of sushi that he creates.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "SpaCy = TextPreprocessSpaCy(reviews[0:1000])\n",
    "end = time.time()\n",
    "print(\"{} \\n --SpaCy Run time: {}s\".format(SpaCy[40],(end-start)))\n",
    "\n",
    "start = time.time()\n",
    "NLTK = TextPreprocessNLTK(reviews[0:1000])\n",
    "end = time.time()\n",
    "print(\"\\n{} \\n --NLTK Run time: {}s\".format(NLTK[40],(end-start)))\n",
    "\n",
    "print(\"\\n{}\".format(reviews[40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 40min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews_spacy = TextPreprocessSpaCy(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path ='C:\\\\Users\\\\schapira.d\\\\Desktop\\\\Data Science Meetup\\\\tokens.pkl' \n",
    "with open(path,'wb') as f:\n",
    "    pickle.dump(reviews_spacy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#load preprocessed dataset:\n",
    "import pickle\n",
    "path_tokens ='C:\\\\Users\\\\schapira.d\\\\Desktop\\\\Data Science Meetup\\\\tokens_spacy.pkl' \n",
    "with open(path_tokens,'rb') as f:\n",
    "    reviews_spacy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrases model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Phrases Modelling\n",
    "bigram_model = Phrases(reviews_spacy,min_count=25)\n",
    "bigram_phraser = Phraser(bigram_model)\n",
    "trigram_model = Phrases(bigram_phraser[reviews_spacy],min_count=25)\n",
    "trigram_phraser = Phraser(trigram_model)\n",
    "\n",
    "reviews_trigram = list(trigram_phraser[bigram_phraser[reviews_spacy]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path ='C:\\\\Users\\\\schapira.d\\\\Desktop\\\\Data Science Meetup\\\\phrases.pkl' \n",
    "with open(path,'wb') as f:\n",
    "    pickle.dump(reviews_trigram, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'place', 'sushi', 'area', 'everything', 'fresh', 'chef', 'pride', 'piece', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "print(reviews_trigram[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>stars_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>favorite</td>\n",
       "      <td>vXEZ-r6fah-5Fjt3a6c-Gw</td>\n",
       "      <td>\"The Cheesecake Factory\"</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>American (Traditional);Desserts;Food;American ...</td>\n",
       "      <td>One of my favorite places too take the kids wh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place</td>\n",
       "      <td>vXEZ-r6fah-5Fjt3a6c-Gw</td>\n",
       "      <td>\"The Cheesecake Factory\"</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>American (Traditional);Desserts;Food;American ...</td>\n",
       "      <td>One of my favorite places too take the kids wh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kid</td>\n",
       "      <td>vXEZ-r6fah-5Fjt3a6c-Gw</td>\n",
       "      <td>\"The Cheesecake Factory\"</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>American (Traditional);Desserts;Food;American ...</td>\n",
       "      <td>One of my favorite places too take the kids wh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>college</td>\n",
       "      <td>vXEZ-r6fah-5Fjt3a6c-Gw</td>\n",
       "      <td>\"The Cheesecake Factory\"</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>American (Traditional);Desserts;Food;American ...</td>\n",
       "      <td>One of my favorite places too take the kids wh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>holiday</td>\n",
       "      <td>vXEZ-r6fah-5Fjt3a6c-Gw</td>\n",
       "      <td>\"The Cheesecake Factory\"</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>American (Traditional);Desserts;Food;American ...</td>\n",
       "      <td>One of my favorite places too take the kids wh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Phrases             business_id                      name        city  \\\n",
       "0  favorite  vXEZ-r6fah-5Fjt3a6c-Gw  \"The Cheesecake Factory\"  Pittsburgh   \n",
       "1     place  vXEZ-r6fah-5Fjt3a6c-Gw  \"The Cheesecake Factory\"  Pittsburgh   \n",
       "2       kid  vXEZ-r6fah-5Fjt3a6c-Gw  \"The Cheesecake Factory\"  Pittsburgh   \n",
       "3   college  vXEZ-r6fah-5Fjt3a6c-Gw  \"The Cheesecake Factory\"  Pittsburgh   \n",
       "4   holiday  vXEZ-r6fah-5Fjt3a6c-Gw  \"The Cheesecake Factory\"  Pittsburgh   \n",
       "\n",
       "                                          categories  \\\n",
       "0  American (Traditional);Desserts;Food;American ...   \n",
       "1  American (Traditional);Desserts;Food;American ...   \n",
       "2  American (Traditional);Desserts;Food;American ...   \n",
       "3  American (Traditional);Desserts;Food;American ...   \n",
       "4  American (Traditional);Desserts;Food;American ...   \n",
       "\n",
       "                                                text  stars_x  \n",
       "0  One of my favorite places too take the kids wh...        4  \n",
       "1  One of my favorite places too take the kids wh...        4  \n",
       "2  One of my favorite places too take the kids wh...        4  \n",
       "3  One of my favorite places too take the kids wh...        4  \n",
       "4  One of my favorite places too take the kids wh...        4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming to df for unstacking and join\n",
    "df_phrases = pd.DataFrame({\"Phrases\" : reviews_trigram}).head(100000)\n",
    "\n",
    "#Unstacking...\n",
    "df = pd.DataFrame({'Index':np.repeat(df_phrases.index.values, df_phrases.Phrases.str.len()),\n",
    "              'Phrases':np.concatenate(df_phrases.Phrases.values)})\n",
    "df.set_index('Index', inplace = True)\n",
    "\n",
    "#Joining with full data\n",
    "reviews_phrases = pd.merge(df,reviews_df.head(100000),left_index=True,right_index=True).reset_index(drop=True)\n",
    "pd.to_numeric(reviews_phrases.stars_x)\n",
    "\n",
    "reviews_phrases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pivot phrases by avg. rating\n",
    "phrases = pd.pivot_table(reviews_phrases, index='Phrases',aggfunc={'stars_x':[np.mean,len]})\n",
    "phrases.columns = phrases.columns.to_series().str.join('_')\n",
    "df = phrases.sort_values('stars_x_mean',ascending=False)\n",
    "df.columns = ['term_frequency','avg_rating']\n",
    "df = df[df.term_frequency > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phrases</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recommend</th>\n",
       "      <td>376</td>\n",
       "      <td>4.643617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love_love</th>\n",
       "      <td>133</td>\n",
       "      <td>4.639098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_gem</th>\n",
       "      <td>423</td>\n",
       "      <td>4.626478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal_favorite</th>\n",
       "      <td>152</td>\n",
       "      <td>4.611842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>857</td>\n",
       "      <td>4.588098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>462</td>\n",
       "      <td>4.577922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worth_penny</th>\n",
       "      <td>165</td>\n",
       "      <td>4.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impeccable</th>\n",
       "      <td>352</td>\n",
       "      <td>4.571023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incredible</th>\n",
       "      <td>1432</td>\n",
       "      <td>4.567039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenomenal</th>\n",
       "      <td>724</td>\n",
       "      <td>4.563536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hooked</th>\n",
       "      <td>142</td>\n",
       "      <td>4.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfection</th>\n",
       "      <td>1246</td>\n",
       "      <td>4.534510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolute_favorite</th>\n",
       "      <td>126</td>\n",
       "      <td>4.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>divine</th>\n",
       "      <td>302</td>\n",
       "      <td>4.513245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrumptious</th>\n",
       "      <td>197</td>\n",
       "      <td>4.507614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   term_frequency  avg_rating\n",
       "Phrases                                      \n",
       "recommend                     376    4.643617\n",
       "love_love                     133    4.639098\n",
       "hidden_gem                    423    4.626478\n",
       "personal_favorite             152    4.611842\n",
       "gem                           857    4.588098\n",
       "best                          462    4.577922\n",
       "worth_penny                   165    4.575758\n",
       "impeccable                    352    4.571023\n",
       "incredible                   1432    4.567039\n",
       "phenomenal                    724    4.563536\n",
       "hooked                        142    4.549296\n",
       "perfection                   1246    4.534510\n",
       "absolute_favorite             126    4.523810\n",
       "divine                        302    4.513245\n",
       "scrumptious                   197    4.507614"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top phrases with highest avg. rating\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phrases</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nasty</th>\n",
       "      <td>420</td>\n",
       "      <td>1.890476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasteless</th>\n",
       "      <td>543</td>\n",
       "      <td>1.858195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inedible</th>\n",
       "      <td>323</td>\n",
       "      <td>1.820433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terrible</th>\n",
       "      <td>2225</td>\n",
       "      <td>1.788315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pathetic</th>\n",
       "      <td>118</td>\n",
       "      <td>1.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rude</th>\n",
       "      <td>1912</td>\n",
       "      <td>1.775628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>1128</td>\n",
       "      <td>1.763298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apology</th>\n",
       "      <td>355</td>\n",
       "      <td>1.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horrible</th>\n",
       "      <td>2039</td>\n",
       "      <td>1.680235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacceptable</th>\n",
       "      <td>164</td>\n",
       "      <td>1.621951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusting</th>\n",
       "      <td>666</td>\n",
       "      <td>1.575075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filthy</th>\n",
       "      <td>152</td>\n",
       "      <td>1.572368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unprofessional</th>\n",
       "      <td>206</td>\n",
       "      <td>1.543689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poisoning</th>\n",
       "      <td>215</td>\n",
       "      <td>1.446512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refund</th>\n",
       "      <td>206</td>\n",
       "      <td>1.310680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                term_frequency  avg_rating\n",
       "Phrases                                   \n",
       "nasty                      420    1.890476\n",
       "tasteless                  543    1.858195\n",
       "inedible                   323    1.820433\n",
       "terrible                  2225    1.788315\n",
       "pathetic                   118    1.779661\n",
       "rude                      1912    1.775628\n",
       "awful                     1128    1.763298\n",
       "apology                    355    1.760563\n",
       "horrible                  2039    1.680235\n",
       "unacceptable               164    1.621951\n",
       "disgusting                 666    1.575075\n",
       "filthy                     152    1.572368\n",
       "unprofessional             206    1.543689\n",
       "poisoning                  215    1.446512\n",
       "refund                     206    1.310680"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top phrases with lowest avg. rating\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# turn tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(reviews_trigram)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "dictionary.compactify()\n",
    "\n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(i) for i in reviews_trigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 22min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#where the magic happens\n",
    "lda_model = gensim.models.ldamulticore.LdaMulticore(corpus,\n",
    "                                                    num_topics=50, \n",
    "                                                    id2word=dictionary, \n",
    "                                                    workers=3, passes=5)\n",
    "\n",
    "lda_model.save('C:\\\\Users\\\\schapira.d\\\\Desktop\\\\Data Science Meetup\\\\lda_505.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "lda_model = models.LdaModel.load('C:\\\\Users\\\\schapira.d\\\\Desktop\\\\Data Science Meetup\\\\lda_50.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.158*\"small\" + 0.151*\"portion\" + 0.106*\"large\" + 0.103*\"huge\" + 0.070*\"size\"'),\n",
       " (1,\n",
       "  '0.174*\"-pron-\" + 0.077*\"husband\" + 0.060*\"wife\" + 0.048*\"kid\" + 0.048*\"family\"'),\n",
       " (2,\n",
       "  '0.068*\"pasta\" + 0.061*\"bread\" + 0.055*\"italian\" + 0.054*\"sauce\" + 0.032*\"salad\"'),\n",
       " (3,\n",
       "  '0.124*\"cheese\" + 0.043*\"onion\" + 0.040*\"bacon\" + 0.026*\"sauce\" + 0.016*\"little\"'),\n",
       " (4,\n",
       "  '0.080*\"coffee\" + 0.048*\"tea\" + 0.038*\"drink\" + 0.038*\"water\" + 0.037*\"cup\"'),\n",
       " (5,\n",
       "  '0.074*\"appetizer\" + 0.052*\"dinner\" + 0.047*\"entree\" + 0.034*\"meal\" + 0.027*\"dessert\"'),\n",
       " (6,\n",
       "  '0.067*\"order\" + 0.059*\"service\" + 0.054*\"minute\" + 0.052*\"time\" + 0.034*\"server\"'),\n",
       " (7,\n",
       "  '0.090*\"vegan\" + 0.077*\"crepe\" + 0.048*\"late_night\" + 0.047*\"takeout\" + 0.040*\"shake\"'),\n",
       " (8,\n",
       "  '0.088*\"dessert\" + 0.059*\"sweet\" + 0.046*\"cake\" + 0.037*\"ice_cream\" + 0.034*\"chocolate\"'),\n",
       " (9,\n",
       "  '0.032*\"guy\" + 0.025*\"thing\" + 0.024*\"people\" + 0.021*\"way\" + 0.020*\"time\"'),\n",
       " (10,\n",
       "  '0.145*\"waffle\" + 0.018*\"traffic\" + 0.016*\"shopping_center\" + 0.015*\"challenge\" + 0.014*\"syrup\"'),\n",
       " (11,\n",
       "  '0.171*\"street\" + 0.045*\"quesadilla\" + 0.041*\"airport\" + 0.040*\"movie\" + 0.038*\"rock\"'),\n",
       " (12,\n",
       "  '0.106*\"dish\" + 0.043*\"flavor\" + 0.015*\"menu\" + 0.015*\"delicious\" + 0.014*\"taste\"'),\n",
       " (13,\n",
       "  '0.110*\"lobster\" + 0.030*\"gelato\" + 0.026*\"partner\" + 0.014*\"bank\" + 0.013*\"top\"'),\n",
       " (14,\n",
       "  '0.098*\"taco\" + 0.053*\"mexican\" + 0.039*\"burrito\" + 0.033*\"salsa\" + 0.024*\"chip\"'),\n",
       " (15, '0.030*\"et\" + 0.023*\"la\" + 0.018*\"par\" + 0.013*\"mai\" + 0.013*\"resto\"'),\n",
       " (16,\n",
       "  '0.154*\"meat\" + 0.066*\"veggie\" + 0.037*\"vegetarian\" + 0.027*\"fresh\" + 0.022*\"option\"'),\n",
       " (17,\n",
       "  '0.187*\"chicken\" + 0.053*\"spicy\" + 0.048*\"rice\" + 0.034*\"sauce\" + 0.028*\"dish\"'),\n",
       " (18,\n",
       "  '0.044*\"bomb\" + 0.037*\"gluten_free\" + 0.029*\"stick\" + 0.027*\"1st\" + 0.018*\"pricy\"'),\n",
       " (19,\n",
       "  '0.145*\"price\" + 0.059*\"buffet\" + 0.038*\"cheap\" + 0.036*\"worth\" + 0.034*\"quality\"'),\n",
       " (20,\n",
       "  '0.162*\"sushi\" + 0.104*\"roll\" + 0.090*\"fish\" + 0.041*\"fresh\" + 0.027*\"chef\"'),\n",
       " (21,\n",
       "  '0.117*\"breakfast\" + 0.072*\"egg\" + 0.046*\"brunch\" + 0.032*\"pancake\" + 0.026*\"morning\"'),\n",
       " (22,\n",
       "  '0.050*\"dip\" + 0.026*\"buddy\" + 0.025*\"organic\" + 0.020*\"everybody\" + 0.017*\"king\"'),\n",
       " (23,\n",
       "  '0.296*\"location\" + 0.035*\"new\" + 0.034*\"chain\" + 0.028*\"downtown\" + 0.027*\"parking\"'),\n",
       " (24,\n",
       "  '0.037*\"nice\" + 0.024*\"cool\" + 0.021*\"little\" + 0.019*\"fun\" + 0.019*\"atmosphere\"'),\n",
       " (25,\n",
       "  '0.103*\"dog\" + 0.022*\"sun\" + 0.017*\"hotdog\" + 0.013*\"share\" + 0.012*\"hub\"'),\n",
       " (26,\n",
       "  '0.183*\"restaurant\" + 0.058*\"chinese\" + 0.053*\"style\" + 0.047*\"authentic\" + 0.037*\"dish\"'),\n",
       " (27,\n",
       "  '0.077*\"menu\" + 0.036*\"item\" + 0.031*\"time\" + 0.027*\"restaurant\" + 0.018*\"thing\"'),\n",
       " (28,\n",
       "  '0.062*\"room\" + 0.044*\"hotel\" + 0.024*\"game\" + 0.023*\"strip\" + 0.019*\"bathroom\"'),\n",
       " (29,\n",
       "  '0.081*\"sauce\" + 0.073*\"wing\" + 0.046*\"pork\" + 0.032*\"bbq\" + 0.030*\"meat\"'),\n",
       " (30,\n",
       "  '0.102*\"bar\" + 0.072*\"drink\" + 0.068*\"beer\" + 0.049*\"great\" + 0.026*\"bartender\"'),\n",
       " (31,\n",
       "  '0.042*\"french\" + 0.039*\"vegas\" + 0.029*\"con\" + 0.027*\"favor\" + 0.022*\"bitter\"'),\n",
       " (32,\n",
       "  '0.098*\"korean\" + 0.051*\"grill\" + 0.042*\"sick\" + 0.038*\"cooking\" + 0.033*\"market\"'),\n",
       " (33,\n",
       "  '0.027*\"nothing_special\" + 0.027*\"soooo\" + 0.025*\"cauliflower\" + 0.021*\"boss\" + 0.018*\"fall\"'),\n",
       " (34,\n",
       "  '0.053*\"great\" + 0.052*\"amazing\" + 0.046*\"-pron-\" + 0.046*\"service\" + 0.038*\"server\"'),\n",
       " (35,\n",
       "  '0.089*\"bad\" + 0.054*\"ok\" + 0.043*\"star\" + 0.042*\"service\" + 0.031*\"bland\"'),\n",
       " (36,\n",
       "  '0.147*\"staff\" + 0.132*\"friendly\" + 0.058*\"great\" + 0.055*\"awesome\" + 0.043*\"nice\"'),\n",
       " (37,\n",
       "  '0.151*\"time\" + 0.056*\"line\" + 0.054*\"worth\" + 0.049*\"long\" + 0.046*\"wait\"'),\n",
       " (38,\n",
       "  '0.252*\"great\" + 0.154*\"service\" + 0.052*\"excellent\" + 0.030*\"friendly\" + 0.022*\"fast\"'),\n",
       " (39,\n",
       "  '0.127*\"table\" + 0.032*\"restaurant\" + 0.029*\"party\" + 0.024*\"people\" + 0.021*\"reservation\"'),\n",
       " (40,\n",
       "  '0.268*\"pizza\" + 0.032*\"delivery\" + 0.031*\"crust\" + 0.028*\"slice\" + 0.027*\"topping\"'),\n",
       " (41,\n",
       "  '0.035*\"bakery\" + 0.030*\"fix\" + 0.027*\"cookie\" + 0.021*\"sport\" + 0.018*\"cupcake\"'),\n",
       " (42,\n",
       "  '0.070*\"soup\" + 0.055*\"noodle\" + 0.042*\"bowl\" + 0.029*\"beef\" + 0.026*\"rice\"'),\n",
       " (43,\n",
       "  '0.116*\"%\" + 0.090*\"man\" + 0.016*\"waren\" + 0.011*\"wurde\" + 0.011*\"sandwhich\"'),\n",
       " (44,\n",
       "  '0.157*\"steak\" + 0.056*\"potato\" + 0.034*\"side\" + 0.028*\"salad\" + 0.022*\"meat\"'),\n",
       " (45,\n",
       "  '0.126*\"customer\" + 0.062*\"service\" + 0.039*\"employee\" + 0.035*\"business\" + 0.033*\"manager\"'),\n",
       " (46, '0.043*\"und\" + 0.020*\"das\" + 0.020*\"ist\" + 0.019*\"war\" + 0.019*\"der\"'),\n",
       " (47,\n",
       "  '0.205*\"shrimp\" + 0.115*\"seafood\" + 0.058*\"oyster\" + 0.053*\"crab\" + 0.020*\"fresh\"'),\n",
       " (48,\n",
       "  '0.278*\"burger\" + 0.189*\"fry\" + 0.028*\"bun\" + 0.018*\"poutine\" + 0.018*\"-pron-\"'),\n",
       " (49,\n",
       "  '0.146*\"lunch\" + 0.127*\"sandwich\" + 0.098*\"salad\" + 0.019*\"-pron-\" + 0.018*\"fresh\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(num_words=5,num_topics=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TopicDetection(doc,min_topic_freq,topn):\n",
    "    \"\"\"\n",
    "    Runs LDA against a document and returns most dominant topics & top keywords\n",
    "    associated with topics. \n",
    "    \"\"\"\n",
    "    \n",
    "    doc_tokens = TextPreprocessSpaCy(doc)[0] #spaCy preprocess\n",
    "    doc_trigram = list(trigram_phraser[bigram_phraser[doc_tokens]]) # phrase model\n",
    "    doc_bow = dictionary.doc2bow(doc_trigram) #create bow representation\n",
    "    doc_lda = lda_model[doc_bow] # run LDA on doc\n",
    "    \n",
    "    #create columns for output df\n",
    "    topic_num = [x[0] for x in doc_lda]\n",
    "    topic_freq = [x[1] for x in doc_lda]\n",
    "    topic_keywords = []\n",
    "    for i in doc_lda:\n",
    "        keywords = [x[0] for x in lda_model.show_topic(i[0],topn=topn)]\n",
    "        topic_keywords.append(keywords)\n",
    "    \n",
    "    headers = ['topic_num','topic_freq','topic_keywords']\n",
    "    df = pd.DataFrame(list(zip(topic_num, topic_freq, topic_keywords)),columns=headers)\n",
    "    df = df[df.topic_freq>min_topic_freq].sort_values('topic_freq',ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 203 ms\n",
      "   topic_num  topic_freq                               topic_keywords\n",
      "0         38    0.268456  [great, service, excellent, friendly, fast]\n",
      "1          2    0.178915        [pasta, bread, italian, sauce, salad]\n",
      "2          5    0.148292   [appetizer, dinner, entree, meal, dessert]\n",
      "3         34    0.131870    [great, amazing, -pron-, service, server]\n",
      "\n",
      "[\"Angela's is probably my favorite place in Charlotte and certainly the best Italian food around. If I lived closer I'd eat here all the time.\\n\\nEverything I've had here has been delicious. I typically get the Veal Parm. It's tasty and tender. I've also had spaghetti, gnocchi, and chicken Parm, and they have all been outstanding. I can also vouch for the eggplant rollatini - one of my wife's favorites. \\n\\nThe appetizers have been great.  We've had the calamari and the mozzarella caprese on several occasions, and they have been great. \\n\\nI don't usually get dessert, although I had a cannoli the once. Home run!!\\n\\nTo top all of that off, the prices here are very reasonable. Most entrees are in the $10-15 range.  You're getting the best Italian food in the area for a price that's almost half of what other joints are charging.\\n\\nAngela's is a can't miss!\"]\n"
     ]
    }
   ],
   "source": [
    "#Reviews - 2,30 german,70\n",
    "text = [reviews[70]]\n",
    "%time topic = TopicDetection(text,0.1,5)\n",
    "print(\"{}\\n\\n{}\".format(topic,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   topic_num  topic_freq                                     topic_keywords\n",
      "0         20    0.361946         [sushi, roll, fish, fresh, chef, japanese]\n",
      "1         19    0.286807  [price, buffet, cheap, worth, quality, expensive]\n",
      "2          1    0.186291         [-pron-, husband, wife, kid, family, time]\n",
      "\n",
      "['My son loves yoyo sushi, the rolls are amazing and fresh but prices are a bit high']\n"
     ]
    }
   ],
   "source": [
    "text = ['My son loves yoyo sushi, the rolls are amazing and fresh but prices are a bit high']\n",
    "topic = TopicDetection(text,0.1,6)\n",
    "print(\"{}\\n\\n{}\".format(topic,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   topic_num  topic_freq                                 topic_keywords\n",
      "0         15       0.505             [et, la, par, mai, resto, service]\n",
      "1          2       0.255  [pasta, bread, italian, sauce, salad, tomato]\n",
      "\n",
      "['Une baguette de pain ou simplement baguette est une variété de pain, reconnaissable à sa forme allongée']\n"
     ]
    }
   ],
   "source": [
    "text = ['Une baguette de pain ou simplement baguette est une variété de pain, reconnaissable à sa forme allongée']\n",
    "topic = TopicDetection(text,0.1,6)\n",
    "print(\"{}\\n\\n{}\".format(topic,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function forked from:\n",
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=reviews, ratings=ratings):\n",
    "    \"\"\"\n",
    "    Extract dominant topic from each document and append original text & rating\n",
    "    \"\"\"\n",
    "    \n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text and rating to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    ratings = pd.Series(ratings)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents, ratings], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "#Sample from original data -optional so it runs quicker-\n",
    "corpus_sample, reviews_sample, ratings_sample = zip(*random.sample(list(zip(corpus, reviews, ratings)), 10000))\n",
    "\n",
    "#Run fuction\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, \n",
    "                                                  corpus=corpus_sample, \n",
    "                                                  texts=reviews_sample,\n",
    "                                                  ratings=ratings_sample)\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text', 'Rating']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords_unique</th>\n",
       "      <th>Rating_len</th>\n",
       "      <th>Rating_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>great, amazing, -pron-, service, server, exper...</td>\n",
       "      <td>823</td>\n",
       "      <td>4.554070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>staff, friendly, great, awesome, nice, clean, ...</td>\n",
       "      <td>459</td>\n",
       "      <td>4.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.0</th>\n",
       "      <td>great, service, excellent, friendly, fast, atm...</td>\n",
       "      <td>739</td>\n",
       "      <td>4.495264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>dish, flavor, menu, delicious, taste, bite, te...</td>\n",
       "      <td>227</td>\n",
       "      <td>4.242291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>dessert, sweet, cake, ice_cream, chocolate, de...</td>\n",
       "      <td>113</td>\n",
       "      <td>4.088496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>meat, veggie, vegetarian, fresh, option, gyro,...</td>\n",
       "      <td>112</td>\n",
       "      <td>4.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.0</th>\n",
       "      <td>lunch, sandwich, salad, -pron-, fresh, special...</td>\n",
       "      <td>318</td>\n",
       "      <td>3.987421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>small, portion, large, huge, size, big, portio...</td>\n",
       "      <td>32</td>\n",
       "      <td>3.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>restaurant, chinese, style, authentic, dish, f...</td>\n",
       "      <td>133</td>\n",
       "      <td>3.962406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>sauce, wing, pork, bbq, meat, rib, chicken, ho...</td>\n",
       "      <td>219</td>\n",
       "      <td>3.949772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>breakfast, egg, brunch, pancake, morning, -pro...</td>\n",
       "      <td>326</td>\n",
       "      <td>3.923313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>pizza, delivery, crust, slice, topping, pie, c...</td>\n",
       "      <td>282</td>\n",
       "      <td>3.918440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>und, das, ist, war, der, nicht, hat, mit, aber...</td>\n",
       "      <td>71</td>\n",
       "      <td>3.887324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>bar, drink, beer, great, bartender, happy_hour...</td>\n",
       "      <td>474</td>\n",
       "      <td>3.873418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>time, line, worth, long, wait, hour, busy, day...</td>\n",
       "      <td>317</td>\n",
       "      <td>3.870662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>sushi, roll, fish, fresh, chef, japanese, salm...</td>\n",
       "      <td>207</td>\n",
       "      <td>3.855072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>taco, mexican, burrito, salsa, chip, bean, mar...</td>\n",
       "      <td>324</td>\n",
       "      <td>3.836420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>nice, cool, little, fun, atmosphere, decor, mu...</td>\n",
       "      <td>397</td>\n",
       "      <td>3.836272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>et, la, par, mai, resto, service, pas, e, qui, à</td>\n",
       "      <td>54</td>\n",
       "      <td>3.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>coffee, tea, drink, water, cup, cafe, shop, ic...</td>\n",
       "      <td>122</td>\n",
       "      <td>3.803279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.0</th>\n",
       "      <td>burger, fry, bun, poutine, -pron-, patty, onio...</td>\n",
       "      <td>233</td>\n",
       "      <td>3.802575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>chicken, spicy, rice, sauce, dish, curry, indi...</td>\n",
       "      <td>325</td>\n",
       "      <td>3.787692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>appetizer, dinner, entree, meal, dessert, -pro...</td>\n",
       "      <td>174</td>\n",
       "      <td>3.781609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-pron-, husband, wife, kid, family, time, year...</td>\n",
       "      <td>147</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>location, new, chain, downtown, parking, origi...</td>\n",
       "      <td>35</td>\n",
       "      <td>3.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>pasta, bread, italian, sauce, salad, tomato, m...</td>\n",
       "      <td>84</td>\n",
       "      <td>3.654762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>soup, noodle, bowl, beef, rice, raman, broth, ...</td>\n",
       "      <td>336</td>\n",
       "      <td>3.651786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>menu, item, time, restaurant, thing, option, r...</td>\n",
       "      <td>555</td>\n",
       "      <td>3.560360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.0</th>\n",
       "      <td>steak, potato, side, salad, meat, butter, cut,...</td>\n",
       "      <td>97</td>\n",
       "      <td>3.556701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>cheese, onion, bacon, sauce, little, bread, pi...</td>\n",
       "      <td>75</td>\n",
       "      <td>3.386667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>price, buffet, cheap, worth, quality, expensiv...</td>\n",
       "      <td>272</td>\n",
       "      <td>3.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>guy, thing, people, way, time, day, review, li...</td>\n",
       "      <td>297</td>\n",
       "      <td>3.232323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>room, hotel, game, strip, bathroom, casino, da...</td>\n",
       "      <td>63</td>\n",
       "      <td>3.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>table, restaurant, party, people, reservation,...</td>\n",
       "      <td>348</td>\n",
       "      <td>2.945402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>order, service, minute, time, server, waitress...</td>\n",
       "      <td>730</td>\n",
       "      <td>2.131507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>customer, service, employee, business, manager...</td>\n",
       "      <td>181</td>\n",
       "      <td>2.116022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>bad, ok, star, service, bland, average, cold, ...</td>\n",
       "      <td>250</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Keywords_unique  Rating_len  \\\n",
       "Dominant_Topic                                                                  \n",
       "34.0            great, amazing, -pron-, service, server, exper...         823   \n",
       "36.0            staff, friendly, great, awesome, nice, clean, ...         459   \n",
       "38.0            great, service, excellent, friendly, fast, atm...         739   \n",
       "12.0            dish, flavor, menu, delicious, taste, bite, te...         227   \n",
       "8.0             dessert, sweet, cake, ice_cream, chocolate, de...         113   \n",
       "16.0            meat, veggie, vegetarian, fresh, option, gyro,...         112   \n",
       "49.0            lunch, sandwich, salad, -pron-, fresh, special...         318   \n",
       "0.0             small, portion, large, huge, size, big, portio...          32   \n",
       "26.0            restaurant, chinese, style, authentic, dish, f...         133   \n",
       "29.0            sauce, wing, pork, bbq, meat, rib, chicken, ho...         219   \n",
       "21.0            breakfast, egg, brunch, pancake, morning, -pro...         326   \n",
       "40.0            pizza, delivery, crust, slice, topping, pie, c...         282   \n",
       "46.0            und, das, ist, war, der, nicht, hat, mit, aber...          71   \n",
       "30.0            bar, drink, beer, great, bartender, happy_hour...         474   \n",
       "37.0            time, line, worth, long, wait, hour, busy, day...         317   \n",
       "20.0            sushi, roll, fish, fresh, chef, japanese, salm...         207   \n",
       "14.0            taco, mexican, burrito, salsa, chip, bean, mar...         324   \n",
       "24.0            nice, cool, little, fun, atmosphere, decor, mu...         397   \n",
       "15.0             et, la, par, mai, resto, service, pas, e, qui, à          54   \n",
       "4.0             coffee, tea, drink, water, cup, cafe, shop, ic...         122   \n",
       "48.0            burger, fry, bun, poutine, -pron-, patty, onio...         233   \n",
       "17.0            chicken, spicy, rice, sauce, dish, curry, indi...         325   \n",
       "5.0             appetizer, dinner, entree, meal, dessert, -pro...         174   \n",
       "1.0             -pron-, husband, wife, kid, family, time, year...         147   \n",
       "23.0            location, new, chain, downtown, parking, origi...          35   \n",
       "2.0             pasta, bread, italian, sauce, salad, tomato, m...          84   \n",
       "42.0            soup, noodle, bowl, beef, rice, raman, broth, ...         336   \n",
       "27.0            menu, item, time, restaurant, thing, option, r...         555   \n",
       "44.0            steak, potato, side, salad, meat, butter, cut,...          97   \n",
       "3.0             cheese, onion, bacon, sauce, little, bread, pi...          75   \n",
       "19.0            price, buffet, cheap, worth, quality, expensiv...         272   \n",
       "9.0             guy, thing, people, way, time, day, review, li...         297   \n",
       "28.0            room, hotel, game, strip, bathroom, casino, da...          63   \n",
       "39.0            table, restaurant, party, people, reservation,...         348   \n",
       "6.0             order, service, minute, time, server, waitress...         730   \n",
       "45.0            customer, service, employee, business, manager...         181   \n",
       "35.0            bad, ok, star, service, bland, average, cold, ...         250   \n",
       "\n",
       "                Rating_mean  \n",
       "Dominant_Topic               \n",
       "34.0               4.554070  \n",
       "36.0               4.529412  \n",
       "38.0               4.495264  \n",
       "12.0               4.242291  \n",
       "8.0                4.088496  \n",
       "16.0               4.053571  \n",
       "49.0               3.987421  \n",
       "0.0                3.968750  \n",
       "26.0               3.962406  \n",
       "29.0               3.949772  \n",
       "21.0               3.923313  \n",
       "40.0               3.918440  \n",
       "46.0               3.887324  \n",
       "30.0               3.873418  \n",
       "37.0               3.870662  \n",
       "20.0               3.855072  \n",
       "14.0               3.836420  \n",
       "24.0               3.836272  \n",
       "15.0               3.833333  \n",
       "4.0                3.803279  \n",
       "48.0               3.802575  \n",
       "17.0               3.787692  \n",
       "5.0                3.781609  \n",
       "1.0                3.714286  \n",
       "23.0               3.685714  \n",
       "2.0                3.654762  \n",
       "42.0               3.651786  \n",
       "27.0               3.560360  \n",
       "44.0               3.556701  \n",
       "3.0                3.386667  \n",
       "19.0               3.253676  \n",
       "9.0                3.232323  \n",
       "28.0               3.095238  \n",
       "39.0               2.945402  \n",
       "6.0                2.131507  \n",
       "45.0               2.116022  \n",
       "35.0               2.000000  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics = pd.pivot_table(df_dominant_topic,index=['Dominant_Topic'],\n",
    "                           aggfunc={'Rating':[np.mean,len],'Keywords':np.unique})\n",
    "df_topics.columns = df_topics.columns.to_series().str.join('_')\n",
    "df = df_topics.sort_values('Rating_mean',ascending=False)\n",
    "df[df.Rating_len > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
